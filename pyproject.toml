[project]
name = "language-modelling"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "einops>=0.8.1",
    "jaxtyping>=0.3.5",
    "numpy>=2.4.1; sys_platform!='darwin'",
    "numpy>=1.26,<2; sys_platform=='darwin'", # Macs
    "tiktoken>=0.12.0",
    "torch>=2.9.1; sys_platform!='darwin' or platform_machine!='x86_64'",
    "torch~=2.2.2; sys_platform=='darwin' and platform_machine=='x86_64'", # Intel Macs
    "tqdm>=4.67.1",
    "wandb>=0.23.1",
]

[project.optional-dependencies]
gpu = ["torch; sys_platform=='linux' or sys_platform=='win32'"]

[build-system]
requires = ["uv_build>=0.9.23,<0.10.0"]
build-backend = "uv_build"

[tool.uv.build-backend]
module-name = "base_model"
module-root = ""

# route torch to CUDA index when Linxu/Windows (when GPU extra is selected)
[tool.uv.sources]
torch = [
    { index = "pytorch-cu128", extra = "gpu", marker = "sys_platform=='linux' or sys_platform=='win32'" },
]

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
